{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e60ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# ----------------- CONFIG -----------------\n",
    "PARQUET_FILE   = \"Exports-by-branches-of-processing-and-countries-2015-2025.parquet\"\n",
    "\n",
    "LOOKBACK       = 12    # months\n",
    "EPOCHS         = 42\n",
    "BATCH_SIZE     = 12\n",
    "VAL_FRACTION   = 0.2\n",
    "MIN_SERIES_LEN = 40    # minimum months of data per (country, branch)\n",
    "MIN_NONZERO    = 12    # require at least 12 non-zero months (real exports)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# ----------------- HELPERS -----------------\n",
    "def make_sequences(X, y, lookback=12):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - lookback):\n",
    "        Xs.append(X[i:i+lookback])\n",
    "        ys.append(y[i+lookback])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "def calculate_wape(y_true, y_pred):\n",
    "    y_true = np.array(y_true, dtype=float)\n",
    "    y_pred = np.array(y_pred, dtype=float)\n",
    "    denom = np.sum(np.abs(y_true))\n",
    "    if denom == 0:\n",
    "        return np.nan\n",
    "    return np.sum(np.abs(y_true - y_pred)) / denom * 100.0\n",
    "\n",
    "def build_lstm_model(input_shape):\n",
    "    # input_shape = (lookback, num_features)\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# ----------------- DATA LOADING -----------------\n",
    "def load_all_series(country_filter=\"United States\"):\n",
    "    \"\"\"\n",
    "    Load the parquet and build a long DataFrame:\n",
    "    Country, Branches, date, value (Fob value only).\n",
    "    If country_filter is None, uses ALL countries.\n",
    "    \"\"\"\n",
    "    df = pd.read_parquet(PARQUET_FILE)\n",
    "    print(\"Parquet columns:\", df.columns)\n",
    "\n",
    "    # Keep only Fob value rows\n",
    "    df = df[df[\"Unit\"] == \"Fob value\"].copy()\n",
    "    df[\"DATA\"] = pd.to_numeric(df[\"DATA\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"DATA\"])\n",
    "\n",
    "    # Month \"2015M01\" -> datetime\n",
    "    df[\"date\"] = pd.to_datetime(\n",
    "        df[\"Month\"].str.replace(\"M\", \"-\") + \"-01\",\n",
    "        format=\"%Y-%m-%d\",\n",
    "        errors=\"coerce\",\n",
    "    )\n",
    "    df = df.dropna(subset=[\"date\"])\n",
    "\n",
    "    if country_filter is not None:\n",
    "        df = df[df[\"Country\"] == country_filter]\n",
    "\n",
    "    # Aggregate per (Country, Branches, date)\n",
    "    df = (\n",
    "        df.groupby([\"Country\", \"Branches\", \"date\"], as_index=False)[\"DATA\"]\n",
    "          .sum()\n",
    "          .rename(columns={\"DATA\": \"value\"})\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTotal rows after filtering: {len(df)}\")\n",
    "    print(\"Example rows:\")\n",
    "    print(df.head())\n",
    "\n",
    "    return df\n",
    "\n",
    "# ----------------- TRAIN ONE SERIES -----------------\n",
    "def train_lstm_for_series(sales_series):\n",
    "    \"\"\"\n",
    "    sales_series: 1D array-like of Fob value over time (monthly, sorted).\n",
    "    Returns dict with r2, wape, model, etc., or None if not enough data.\n",
    "    \"\"\"\n",
    "    sales = np.asarray(sales_series, dtype=float)\n",
    "\n",
    "    # length check\n",
    "    if len(sales) < MIN_SERIES_LEN:\n",
    "        return None\n",
    "\n",
    "    # non-zero export requirement\n",
    "    nonzero_count = np.count_nonzero(sales)\n",
    "    if nonzero_count < MIN_NONZERO:\n",
    "        return None\n",
    "\n",
    "    # constant or almost-constant series -> skip\n",
    "    if np.allclose(sales, sales[0]):\n",
    "        return None\n",
    "\n",
    "    # Features = just the sales series\n",
    "    features = sales.reshape(-1, 1)\n",
    "    targets  = sales.reshape(-1, 1)\n",
    "\n",
    "    # Normalization (like your example)\n",
    "    y_mean = sales.mean()\n",
    "    y_std  = sales.std()\n",
    "    if y_std == 0:\n",
    "        return None\n",
    "\n",
    "    f_mean = features.mean(axis=0)\n",
    "    f_std  = features.std(axis=0)\n",
    "    f_std[f_std == 0] = 1.0\n",
    "\n",
    "    features_n = (features - f_mean) / f_std\n",
    "    targets_n  = (targets  - y_mean) / y_std\n",
    "\n",
    "    # Sequences\n",
    "    X, y = make_sequences(features_n, targets_n, lookback=LOOKBACK)\n",
    "    if len(X) < 10:\n",
    "        return None\n",
    "\n",
    "    # Time-based split (no shuffle)\n",
    "    n_total = len(X)\n",
    "    n_train = int(np.floor(n_total * (1.0 - VAL_FRACTION)))\n",
    "    if n_train < 1 or n_train >= n_total:\n",
    "        return None\n",
    "\n",
    "    X_train, X_val = X[:n_train], X[n_train:]\n",
    "    y_train, y_val = y[:n_train], y[n_train:]\n",
    "\n",
    "    # Build & train model\n",
    "    model = build_lstm_model(input_shape=(LOOKBACK, X.shape[2]))\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        verbose=0  # quiet\n",
    "    )\n",
    "\n",
    "    # Predict & denormalize\n",
    "    y_pred_n = model.predict(X_val, verbose=0)\n",
    "    y_true = y_val * y_std + y_mean\n",
    "    y_pred = y_pred_n * y_std + y_mean\n",
    "\n",
    "    # Metrics\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    wape = calculate_wape(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        \"model\":   model,\n",
    "        \"r2\":      float(r2),\n",
    "        \"wape\":    float(wape),\n",
    "        \"y_mean\":  float(y_mean),\n",
    "        \"y_std\":   float(y_std),\n",
    "        \"n_points\": len(sales),\n",
    "    }\n",
    "\n",
    "# ----------------- RUN ACROSS CATEGORIES -----------------\n",
    "def train_lstm_across_categories(country_filter=\"United States\"):\n",
    "    \"\"\"\n",
    "    Trains one LSTM per (Country, Branches) time series.\n",
    "    Returns:\n",
    "      - results_df: summary DataFrame with metrics\n",
    "      - best_info: dict containing the best model and meta-data\n",
    "    \"\"\"\n",
    "    df = load_all_series(country_filter=country_filter)\n",
    "\n",
    "    results = []\n",
    "    best_info = None\n",
    "\n",
    "    # Get unique countries if no filter\n",
    "    if country_filter is None:\n",
    "        countries = df[\"Country\"].unique()\n",
    "        print(f\"\\nProcessing {len(countries)} countries:\")\n",
    "        for country in countries:\n",
    "            print(f\"- {country}\")\n",
    "\n",
    "    grouped = df.sort_values(\"date\").groupby([\"Country\", \"Branches\"])\n",
    "    total_groups = len(grouped)\n",
    "    current_country = None\n",
    "\n",
    "    print(f\"\\nNumber of (Country, Branch) series: {total_groups}\")\n",
    "\n",
    "    for idx, ((country, branch), sub) in enumerate(grouped, start=1):\n",
    "        # Track country changes\n",
    "        if current_country != country:\n",
    "            current_country = country\n",
    "            print(f\"\\nProcessing country: {country}\")\n",
    "\n",
    "        sales_series = sub[\"value\"].values\n",
    "\n",
    "        info = train_lstm_for_series(sales_series)\n",
    "        if info is None:\n",
    "            continue\n",
    "\n",
    "        results.append({\n",
    "            \"country\":   country,\n",
    "            \"branch\":    branch,\n",
    "            \"n_points\":  info[\"n_points\"],\n",
    "            \"r2\":        info[\"r2\"],\n",
    "            \"wape\":      info[\"wape\"],\n",
    "        })\n",
    "\n",
    "        # Track best model by R²\n",
    "        if (best_info is None) or (info[\"r2\"] > best_info[\"r2\"]):\n",
    "            best_info = {\n",
    "                \"country\": country,\n",
    "                \"branch\":  branch,\n",
    "                **info,\n",
    "            }\n",
    "\n",
    "        # light progress indicator\n",
    "        if idx % 100 == 0:\n",
    "            print(f\"Processed {idx}/{total_groups} series...\")\n",
    "\n",
    "    if not results:\n",
    "        print(\"\\nNo valid series found (not enough data / mostly zero).\")\n",
    "        return pd.DataFrame(), None\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Optionally drop suspicious perfect fits (R² == 1)\n",
    "    results_df = results_df[results_df[\"r2\"] < 0.9999]\n",
    "\n",
    "    # Summary: top 20 by R²\n",
    "    print(\"\\n===== TOP 20 CATEGORIES BY R² (LSTM, Fob value only) =====\")\n",
    "    print(\n",
    "        results_df.sort_values(\"r2\", ascending=False)\n",
    "                  .head(20)\n",
    "                  .to_string(index=False)\n",
    "    )\n",
    "\n",
    "    # Best model info\n",
    "    best_row = results_df.sort_values(\"r2\", ascending=False).iloc[0]\n",
    "    print(\"\\n===== BEST CATEGORY (HIGHEST R²) =====\")\n",
    "    print(f\"Country: {best_row['country']}\")\n",
    "    print(f\"Branch:  {best_row['branch']}\")\n",
    "    print(f\"R²:      {best_row['r2']:.4f}\")\n",
    "    print(f\"WAPE:    {best_row['wape']:.2f}%\")\n",
    "    print(f\"Points:  {best_row['n_points']}\")\n",
    "\n",
    "    return results_df, best_info\n",
    "\n",
    "# ----------------- RUN IT -----------------\n",
    "# Start with one country (cheaper):\n",
    "results_df, best_info = train_lstm_across_categories(country_filter=None)\n",
    "\n",
    "# For ALL countries (very heavy), you can later do:\n",
    "# results_df, best_info = train_lstm_across_categories(country_filter=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
