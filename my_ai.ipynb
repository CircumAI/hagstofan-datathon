{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e60ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation across all countries...\n",
      "\n",
      "Parquet columns: Index(['Branches', 'Country', 'Month', 'Unit', 'DATA'], dtype='object')\n",
      "Parquet columns: Index(['Branches', 'Country', 'Month', 'Unit', 'DATA'], dtype='object')\n",
      "Inflation columns: Index(['Month', 'Consumer price index Index',\n",
      "       'Consumer price index Monthly change, %',\n",
      "       'Consumer price index Annual change, %'],\n",
      "      dtype='object')\n",
      "Inflation columns: Index(['Month', 'Consumer price index Index',\n",
      "       'Consumer price index Monthly change, %',\n",
      "       'Consumer price index Annual change, %'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 4 fields in line 1332, saw 10\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mParserError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 193\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# ================== RUN & SUMMARIZE ==================\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRunning evaluation across all countries...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m results_all = \u001b[43mevaluate_all_countries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m36\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m===== TOP 20 PRODUCTS BY R² (any country, any combo) =====\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    196\u001b[39m top20 = results_all.sort_values(\u001b[33m\"\u001b[39m\u001b[33mr2\u001b[39m\u001b[33m\"\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m).head(\u001b[32m20\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 128\u001b[39m, in \u001b[36mevaluate_all_countries\u001b[39m\u001b[34m(min_samples)\u001b[39m\n\u001b[32m    126\u001b[39m branches = load_branches_all_countries()\n\u001b[32m    127\u001b[39m cpi = load_cpi()\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m fx  = \u001b[43mload_fx\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[38;5;66;03m# Merge CPI + FX on date -> macro feature frame\u001b[39;00m\n\u001b[32m    131\u001b[39m macro = cpi.join(fx, how=\u001b[33m\"\u001b[39m\u001b[33minner\u001b[39m\u001b[33m\"\u001b[39m)   \u001b[38;5;66;03m# index=date, cols: cpi_index, usd_fx\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 81\u001b[39m, in \u001b[36mload_fx\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_fx\u001b[39m():\n\u001b[32m     77\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[33;03m    Load FX file, clean Icelandic decimal-comma format, aggregate to monthly\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[33;03m    average USD rate.\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     fx = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFX_FILE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFX raw columns:\u001b[39m\u001b[33m\"\u001b[39m, fx.columns)\n\u001b[32m     84\u001b[39m     \u001b[38;5;66;03m# Find the date column (it has a BOM in the name)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tf312/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tf312/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tf312/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tf312/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:2061\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mParserError\u001b[39m: Error tokenizing data. C error: Expected 4 fields in line 1332, saw 10\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Evaluate how well CPI and FX explain each product\n",
    "# in every country (using the big parquet file)\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "from IPython.display import display\n",
    "\n",
    "# ---- FILE NAMES (must match your folder) ----\n",
    "PARQUET_FILE = \"Exports-by-branches-of-processing-and-countries-2015-2025.parquet\"\n",
    "CPI_FILE     = \"Inflation-Consumer price index.csv\"\n",
    "FX_FILE      = \"Exchange-rates_2015-2025.csv\"\n",
    "\n",
    "\n",
    "# ----------------- METRIC ---------------------\n",
    "\n",
    "def wape(y_true, y_pred):\n",
    "    \"\"\"Weighted Absolute Percentage Error in %.\"\"\"\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    denom = np.sum(np.abs(y_true))\n",
    "    if denom == 0:\n",
    "        return np.nan\n",
    "    return np.sum(np.abs(y_true - y_pred)) / denom * 100.0\n",
    "\n",
    "\n",
    "# ----------------- LOADERS --------------------\n",
    "\n",
    "def load_branches_all_countries():\n",
    "    \"\"\"\n",
    "    Load the parquet file, keep Fob value, convert Month to datetime,\n",
    "    and keep numeric DATA.\n",
    "    \"\"\"\n",
    "    # If pyarrow is required on your system:\n",
    "    # df = pd.read_parquet(PARQUET_FILE, engine=\"pyarrow\")\n",
    "    df = pd.read_parquet(PARQUET_FILE)\n",
    "    print(\"Parquet columns:\", df.columns)\n",
    "\n",
    "    # Only 'Fob value' rows\n",
    "    df = df[df[\"Unit\"] == \"Fob value\"].copy()\n",
    "\n",
    "    # Month like '2015M01' -> '2015-01-01'\n",
    "    df[\"date\"] = pd.to_datetime(df[\"Month\"].str.replace(\"M\", \"-\") + \"-01\")\n",
    "\n",
    "    # Ensure DATA is numeric\n",
    "    df[\"DATA\"] = pd.to_numeric(df[\"DATA\"], errors=\"coerce\")\n",
    "\n",
    "    # Keep relevant columns and drop NaNs\n",
    "    df = df[[\"Country\", \"Branches\", \"date\", \"DATA\"]].dropna(subset=[\"DATA\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_cpi():\n",
    "    \"\"\"\n",
    "    Load CPI file, convert Month to datetime, return monthly index series.\n",
    "    \"\"\"\n",
    "    cpi = pd.read_csv(CPI_FILE)\n",
    "    print(\"Inflation columns:\", cpi.columns)\n",
    "\n",
    "    cpi[\"date\"] = pd.to_datetime(cpi[\"Month\"].str.replace(\"M\", \"-\") + \"-01\")\n",
    "\n",
    "    cpi = (\n",
    "        cpi[[\"date\", \"Consumer price index Index\"]]\n",
    "        .rename(columns={\"Consumer price index Index\": \"cpi_index\"})\n",
    "        .set_index(\"date\")\n",
    "        .sort_index()\n",
    "    )\n",
    "\n",
    "    return cpi\n",
    "\n",
    "def load_fx():\n",
    "    \"\"\"\n",
    "    Load FX file, clean Icelandic decimal-comma format, aggregate to monthly\n",
    "    average USD rate. Uses python engine + on_bad_lines='skip' to avoid\n",
    "    parser errors on messy rows.\n",
    "    \"\"\"\n",
    "    fx = pd.read_csv(\n",
    "        FX_FILE,\n",
    "        engine=\"python\",   # more tolerant parser\n",
    "        sep=None,          # auto-detect delimiter\n",
    "        on_bad_lines=\"skip\"\n",
    "    )\n",
    "    print(\"FX raw columns:\", fx.columns)\n",
    "\n",
    "    # Find the date column (it has a BOM in the name in your file)\n",
    "    date_col_candidates = [c for c in fx.columns if \"Dagsetning\" in c]\n",
    "    if not date_col_candidates:\n",
    "        raise ValueError(\"Could not find 'Dagsetning' date column in FX file.\")\n",
    "    date_col = date_col_candidates[0]\n",
    "\n",
    "    usd_col = \"Bandaríkjadalur USD miðgengi\"\n",
    "\n",
    "    # Parse dates\n",
    "    fx[date_col] = pd.to_datetime(fx[date_col], dayfirst=True, errors=\"coerce\")\n",
    "\n",
    "    # Clean numeric strings like \"1.234,56\" -> \"1234.56\"\n",
    "    fx[usd_col] = (\n",
    "        fx[usd_col].astype(str)\n",
    "        .str.replace(\" \", \"\", regex=False)\n",
    "        .str.replace(\".\", \"\", regex=False)   # remove thousand separator\n",
    "        .str.replace(\",\", \".\", regex=False)  # decimal comma -> dot\n",
    "    )\n",
    "    fx[usd_col] = pd.to_numeric(fx[usd_col], errors=\"coerce\")\n",
    "\n",
    "    fx = fx.dropna(subset=[date_col, usd_col])\n",
    "\n",
    "    # Aggregate to monthly mean\n",
    "    fx[\"month\"] = fx[date_col].dt.to_period(\"M\").dt.to_timestamp()\n",
    "\n",
    "    fx_month = (\n",
    "        fx.groupby(\"month\")[usd_col]\n",
    "          .mean()\n",
    "          .reset_index()\n",
    "          .rename(columns={\"month\": \"date\", usd_col: \"usd_fx\"})\n",
    "          .set_index(\"date\")\n",
    "          .sort_index()\n",
    "    )\n",
    "\n",
    "    return fx_month\n",
    "\n",
    "\n",
    "# ----------------- EVALUATION --------------------\n",
    "\n",
    "def evaluate_all_countries(min_samples=36):\n",
    "    \"\"\"\n",
    "    For each (Country, Branches), fit simple linear models:\n",
    "      y ~ CPI, y ~ FX, y ~ (CPI + FX)\n",
    "    using monthly data where CPI+FX exist.\n",
    "    Returns a DataFrame with R² and WAPE for each combo.\n",
    "    \"\"\"\n",
    "    branches = load_branches_all_countries()\n",
    "    cpi = load_cpi()\n",
    "    fx  = load_fx()\n",
    "\n",
    "    # Merge CPI + FX on date -> macro feature frame\n",
    "    macro = cpi.join(fx, how=\"inner\")   # index=date, cols: cpi_index, usd_fx\n",
    "    print(\"\\nMacro feature frame head:\")\n",
    "    print(macro.head())\n",
    "\n",
    "    results = []\n",
    "\n",
    "    combos = [\n",
    "        (\"cpi_only\", [\"cpi_index\"]),\n",
    "        (\"fx_only\",  [\"usd_fx\"]),\n",
    "        (\"both\",     [\"cpi_index\", \"usd_fx\"]),\n",
    "    ]\n",
    "\n",
    "    # Loop over every (country, branch) pair\n",
    "    for (country, branch), g in branches.groupby([\"Country\", \"Branches\"]):\n",
    "        # Aggregate to monthly Fob sums\n",
    "        series = (\n",
    "            g.groupby(\"date\")[\"DATA\"]\n",
    "             .sum()\n",
    "             .sort_index()\n",
    "             .rename(\"y\")\n",
    "        )\n",
    "\n",
    "        # Join with macro features\n",
    "        df_join = pd.concat([series, macro], axis=1).dropna()\n",
    "        if len(df_join) < min_samples:\n",
    "            continue  # too little data\n",
    "\n",
    "        y = df_join[\"y\"].astype(float).values\n",
    "\n",
    "        for combo_name, feat_cols in combos:\n",
    "            X = df_join[feat_cols].values\n",
    "\n",
    "            # Standardize features\n",
    "            X_mean = X.mean(axis=0, keepdims=True)\n",
    "            X_std  = X.std(axis=0, keepdims=True)\n",
    "            X_std[X_std == 0] = 1.0\n",
    "            Xn = (X - X_mean) / X_std\n",
    "\n",
    "            # Simple linear regression with Ridge\n",
    "            model = Ridge(alpha=1.0)\n",
    "            model.fit(Xn, y)\n",
    "            y_pred = model.predict(Xn)\n",
    "\n",
    "            r2_val   = r2_score(y, y_pred)\n",
    "            wape_val = wape(y, y_pred)\n",
    "\n",
    "            results.append({\n",
    "                \"country\":       country,\n",
    "                \"branch\":        branch,\n",
    "                \"feature_combo\": combo_name,\n",
    "                \"n_samples\":     len(y),\n",
    "                \"r2\":            r2_val,\n",
    "                \"wape\":          wape_val,\n",
    "            })\n",
    "\n",
    "    res_df = pd.DataFrame(results)\n",
    "    return res_df\n",
    "\n",
    "\n",
    "# ================== RUN & SUMMARIZE ==================\n",
    "\n",
    "print(\"Running evaluation across all countries...\\n\")\n",
    "results_all = evaluate_all_countries(min_samples=36)\n",
    "\n",
    "print(\"\\n===== TOP 20 PRODUCTS BY R² (any country, any combo) =====\")\n",
    "top20 = results_all.sort_values(\"r2\", ascending=False).head(20)\n",
    "display(top20[[\"country\", \"branch\", \"feature_combo\", \"n_samples\", \"r2\", \"wape\"]])\n",
    "\n",
    "print(\"\\n===== BEST COMBO PER (COUNTRY, BRANCH) (sorted by R²) =====\")\n",
    "best_per = (\n",
    "    results_all.sort_values(\"r2\", ascending=False)\n",
    "               .drop_duplicates(subset=[\"country\", \"branch\"])\n",
    ")\n",
    "display(best_per[[\"country\", \"branch\", \"feature_combo\", \"n_samples\", \"r2\", \"wape\"]])\n",
    "\n",
    "# Example: see only United States results\n",
    "print(\"\\n===== UNITED STATES ONLY (sorted by R²) =====\")\n",
    "us_only = results_all[results_all[\"country\"] == \"United States\"] \\\n",
    "                     .sort_values(\"r2\", ascending=False)\n",
    "display(us_only[[\"country\", \"branch\", \"feature_combo\", \"n_samples\", \"r2\", \"wape\"]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
