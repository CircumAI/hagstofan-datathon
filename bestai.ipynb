{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7fb62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "NUMCLASSES = 1000\n",
    "RANGEMULT = 2\n",
    "UNCERTAINITY = 0.0015\n",
    "\n",
    "dev = (NUMCLASSES/RANGEMULT)*UNCERTAINITY\n",
    "vec = np.linspace(0, NUMCLASSES, NUMCLASSES, endpoint=False)\n",
    "def uncertainify(tc):\n",
    "  return stats.norm.pdf(vec, tc, dev)\n",
    "#vec = stats.norm.pdf(vec, 500, 1)\n",
    "target_uncertain_vector = np.array(list(map(uncertainify, [500, 200])))\n",
    "print(target_uncertain_vector[0])\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(target_uncertain_vector[0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efbb172",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Simple test code for a LSTM network using two data files in two runs:\n",
    "#First file:  data1.txt (90 months 2018-2025 total export of services to 250 countries in FOB/MISK)\n",
    "#Second file: data2.txt.(90 months 2018-2025 total export of goods to USA in Tonnes)\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "#------------(HYPER)PARAMETERS-------------\n",
    "LOOKBACK = 12\n",
    "NUMCLASSES = 1000\n",
    "RANGEMULT = 2\n",
    "UNCERTAINITY = 0.001\n",
    "UNCERTAINIFY = False #Enable or disable uncertifying.\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 3\n",
    "LEARNING_RATE = 0.0005\n",
    "\n",
    "ALPHA = 0.1\n",
    "\n",
    "PARQUET_FILE  = \"Exports-by-branches-of-processing-and-countries-2015-2025.parquet\"\n",
    "CPI_FILE      = \"Inflation-Consumer price index.csv\"\n",
    "FX_FILE       = \"Exchange-rates_2015-2025.csv\"\n",
    "\n",
    "TARGET_COUNTRY = \"Sweden\"\n",
    "TARGET_BRANCH  = \"00 Whole fish, fresh, chilled or on ice\"\n",
    "# -----------Initialation and READ DATA Two different Real dataset are used:-------------------\n",
    "# data1= Total sales of services MISK last 90 months,\n",
    "# data3= Export of goods to USA in Tonnes last 90 months\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "np.random.seed(42)\n",
    "months = 90\n",
    "t = np.arange(months)\n",
    "numbers_list = []\n",
    "numbers_list3 = []\n",
    "\n",
    "# -------------------------\n",
    "# Sequence maker function\n",
    "# -------------------------\n",
    "def make_sequences(X, y, y_class, LOOKBACK):\n",
    "    Xs, ys, ycs = [], [], []\n",
    "    for i in range(len(X) - LOOKBACK):\n",
    "        #print(i,\"\\t\", X[i:i+LOOKBACK])             # Commented out print statement\n",
    "        Xs.append(X[i:i+LOOKBACK])\n",
    "        ys.append(y[i+LOOKBACK])\n",
    "        ycs.append(y_class[i+LOOKBACK])\n",
    "    return np.array(Xs), np.array(ys), np.array(ycs)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Calculates: Weighted Absolute Percentage Error (WAPE).\n",
    "# Returns: The WAPE value as a float. Returns 0 if the\n",
    "# sum of actual values is zero.\n",
    "# ------------------------------------------------------\n",
    "def calculate_wape(y_true, y_pred):\n",
    "  y_true = np.array(y_true)                         # y_true: A numpy array or list of actual values.\n",
    "  y_pred = np.array(y_pred)                         # y_pred: A numpy array or list of predicted values.\n",
    "\n",
    "  # Avoid division by zero\n",
    "  if np.sum(np.abs(y_true)) == 0:\n",
    "    return 0\n",
    "  else:\n",
    "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true)) * 100\n",
    "\n",
    "# ---------------- DATA LOADING ----------------\n",
    "def load_exports():\n",
    "    df = pd.read_parquet(PARQUET_FILE)\n",
    "    print(\"Parquet columns:\", df.columns)\n",
    "\n",
    "    # Clean\n",
    "    df[\"Country\"] = (\n",
    "        df[\"Country\"].astype(str)\n",
    "        .str.replace(\"\\xa0\", \" \", regex=False)\n",
    "        .str.strip()\n",
    "    )\n",
    "    df[\"Branches\"] = df[\"Branches\"].astype(str).str.strip()\n",
    "\n",
    "    df[\"date\"] = pd.to_datetime(\n",
    "        df[\"Month\"].astype(str).str.replace(\"M\", \"-\") + \"-01\",\n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "    df = df.dropna(subset=[\"date\"])\n",
    "\n",
    "    # Keep only Fob value + Tonnes\n",
    "    df = df[df[\"Unit\"].isin([\"Fob value\", \"Tonnes\"])].copy()\n",
    "    df[\"DATA\"] = pd.to_numeric(df[\"DATA\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"DATA\"])\n",
    "\n",
    "    # Pivot to columns\n",
    "    df_piv = df.pivot_table(\n",
    "        index=[\"Country\", \"Branches\", \"date\"],\n",
    "        columns=\"Unit\",\n",
    "        values=\"DATA\",\n",
    "        aggfunc=\"sum\"\n",
    "    ).reset_index()\n",
    "\n",
    "    df_piv = df_piv.rename(columns={\"Fob value\": \"fob_value\", \"Tonnes\": \"tonnes\"})\n",
    "    df_piv[\"fob_value\"] = df_piv[\"fob_value\"].fillna(0.0)\n",
    "    df_piv[\"tonnes\"]    = df_piv[\"tonnes\"].fillna(0.0)\n",
    "\n",
    "    # Filter target series\n",
    "    mask = (\n",
    "        (df_piv[\"Country\"] == TARGET_COUNTRY) &\n",
    "        (df_piv[\"Branches\"] == TARGET_BRANCH)\n",
    "    )\n",
    "    series = df_piv[mask].sort_values(\"date\")\n",
    "\n",
    "    if series.empty:\n",
    "        raise ValueError(f\"No data for {TARGET_COUNTRY} - {TARGET_BRANCH}\")\n",
    "\n",
    "    print(\"\\nExports (Sweden, Whole fish) sample:\")\n",
    "    print(series.head())\n",
    "\n",
    "    return series[[\"date\", \"fob_value\", \"tonnes\"]].reset_index(drop=True)\n",
    "\n",
    "def load_cpi():\n",
    "    cpi = pd.read_csv(CPI_FILE)\n",
    "    cpi[\"date\"] = pd.to_datetime(\n",
    "        cpi[\"Month\"].astype(str).str.replace(\"M\", \"-\") + \"-01\",\n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "    cpi[\"cpi_index\"] = pd.to_numeric(\n",
    "        cpi[\"Consumer price index Index\"], errors=\"coerce\"\n",
    "    )\n",
    "    cpi = cpi.dropna(subset=[\"date\", \"cpi_index\"])\n",
    "    return cpi[[\"date\", \"cpi_index\"]].sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "def load_fx():\n",
    "    fx = pd.read_csv(FX_FILE, sep=\";\", engine=\"python\")\n",
    "    date_col = fx.columns[0]\n",
    "    fx[date_col] = pd.to_datetime(fx[date_col], errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "    usd_cols = [c for c in fx.columns if \"Bandaríkjadalur\" in c and \"miðgengi\" in c]\n",
    "    if not usd_cols:\n",
    "        raise ValueError(\"USD mid column not found in FX file.\")\n",
    "    usd_col = usd_cols[0]\n",
    "\n",
    "    fx[\"usd_fx\"] = (\n",
    "        fx[usd_col]\n",
    "        .astype(str)\n",
    "        .str.replace(\".\", \"\", regex=False)\n",
    "        .str.replace(\",\", \".\", regex=False)\n",
    "    )\n",
    "    fx[\"usd_fx\"] = pd.to_numeric(fx[\"usd_fx\"], errors=\"coerce\")\n",
    "\n",
    "    fx = fx.dropna(subset=[date_col, \"usd_fx\"])\n",
    "    fx[\"year_month\"] = fx[date_col].dt.to_period(\"M\")\n",
    "    fx_monthly = fx.groupby(\"year_month\", as_index=False)[\"usd_fx\"].mean()\n",
    "    fx_monthly[\"date\"] = fx_monthly[\"year_month\"].dt.to_timestamp()\n",
    "    return fx_monthly[[\"date\", \"usd_fx\"]].sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "def load_merged_series():\n",
    "    exp_df = load_exports()\n",
    "    cpi_df = load_cpi()\n",
    "    fx_df  = load_fx()\n",
    "\n",
    "    merged = (\n",
    "        exp_df\n",
    "        .merge(cpi_df, on=\"date\", how=\"inner\")\n",
    "        .merge(fx_df,  on=\"date\", how=\"inner\")\n",
    "        .sort_values(\"date\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    print(\"\\nMerged series head (fob, tonnes, cpi, fx):\")\n",
    "    print(merged.head())\n",
    "    print(\"Total months after merge:\", len(merged))\n",
    "    return merged\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Custom loss function:\n",
    "# ----------------------------------------------\n",
    "class UncategoricalCrossEntropyLoss(tf.keras.losses.Loss):\n",
    "  def __init__(self, name=\"uncategorical_cross_entropy_loss\"):\n",
    "    super().__init__(name=name)\n",
    "\n",
    "  def call(self, y_true, y_pred):\n",
    "    yae = tf.abs(y_true-y_pred)\n",
    "    #loss = yae\n",
    "    loss = -tf.math.log(1-yae)\n",
    "    #loss = -y_true*tf.math.log(y_pred)\n",
    "    return tf.reduce_sum(loss)\n",
    "\n",
    "\n",
    "def main():\n",
    "  # 1) Load merged multifeature series for Sweden / branch\n",
    "  merged = load_merged_series()\n",
    "  # merged columns: date, fob_value, tonnes, cpi_index, usd_fx\n",
    "\n",
    "  # 2) Build features: [fob, tonnes, cpi, fx]\n",
    "  fob     = merged[\"fob_value\"].values.astype(float)\n",
    "  tonnes  = merged[\"tonnes\"].values.astype(float)\n",
    "  cpi     = merged[\"cpi_index\"].values.astype(float)\n",
    "  usd_fx  = merged[\"usd_fx\"].values.astype(float)\n",
    "\n",
    "  # Shape: (T, 4)\n",
    "  features = np.stack([fob, tonnes, cpi, usd_fx], axis=1)\n",
    "\n",
    "  # Target we're predicting = FOB value\n",
    "  targets = fob.reshape(-1, 1)\n",
    "\n",
    "  # 3) Normalize features (per feature)\n",
    "  f_mean = features.mean(axis=0)\n",
    "  f_std  = features.std(axis=0)\n",
    "  f_std[f_std == 0] = 1.0\n",
    "  features_n = (features - f_mean) / f_std\n",
    "\n",
    "  # 4) Discretize FOB target into NUMCLASSES (same logic as before)\n",
    "  targets_1d = targets.ravel()\n",
    "  mint = targets_1d.min()\n",
    "  maxt = targets_1d.max()\n",
    "  rng  = (maxt - mint)\n",
    "\n",
    "  if rng == 0:\n",
    "    raise ValueError(\"FOB series is constant; cannot discretize into classes.\")\n",
    "\n",
    "  scale   = (NUMCLASSES / (RANGEMULT * rng))\n",
    "  descale = (RANGEMULT * rng) / NUMCLASSES\n",
    "  base    = NUMCLASSES * ((RANGEMULT - 1) / (2 * RANGEMULT))\n",
    "\n",
    "  def toClasses(x):\n",
    "    return int(scale * (x - mint) + base)\n",
    "\n",
    "  def fromClasses(y):\n",
    "    return mint + descale * (y - base)\n",
    "\n",
    "  target_classes = np.array([toClasses(x) for x in targets_1d])\n",
    "\n",
    "  # 5) Uncertainify / certainify class targets\n",
    "  dev = (NUMCLASSES / RANGEMULT) * UNCERTAINITY\n",
    "\n",
    "  def certainify(tc):\n",
    "    vec = np.zeros(NUMCLASSES)\n",
    "    vec[tc] = 1.0\n",
    "    return vec\n",
    "\n",
    "  vec = np.linspace(0, NUMCLASSES, NUMCLASSES, endpoint=False)\n",
    "  def uncertainify(tc):\n",
    "    return stats.norm.pdf(vec, tc, dev)\n",
    "\n",
    "  if(UNCERTAINIFY):\n",
    "    target_vector = np.array(\n",
    "        [uncertainify(tc) for tc in target_classes]\n",
    "    )\n",
    "  else:\n",
    "    target_vector = np.array(\n",
    "        [certainify(tc) for tc in target_classes]\n",
    "    )\n",
    "\n",
    "  # 6) Build sequences for LSTM (multi-feature input, class-distribution output)\n",
    "  X, y, y_class = make_sequences(\n",
    "      features_n,\n",
    "      target_vector,\n",
    "      target_classes,\n",
    "      LOOKBACK\n",
    "  )\n",
    "\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  X_train, X_val, y_train, y_val, y_train_class, y_val_class = train_test_split(\n",
    "      X, y, y_class, test_size=0.2, shuffle=False\n",
    "  )\n",
    "\n",
    "  # 7) Model (same classification architecture as before)\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(NUMCLASSES, input_shape=(LOOKBACK, X.shape[2])))\n",
    "  model.add(Dense(NUMCLASSES, activation='relu'))\n",
    "  model.add(Dense(NUMCLASSES, activation='softmax'))\n",
    "\n",
    "  if UNCERTAINIFY:\n",
    "    loss = UncategoricalCrossEntropyLoss()\n",
    "  else:\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "  model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "  # 8) Train\n",
    "  history = model.fit(\n",
    "      X_train,\n",
    "      y_train,\n",
    "      validation_data=(X_val, y_val),\n",
    "      epochs=EPOCHS,\n",
    "      batch_size=BATCH_SIZE,\n",
    "      verbose=1\n",
    "  )\n",
    "\n",
    "  # 9) Predictions -> continuous FOB via classes\n",
    "  y_hat = model.predict(X_val, verbose=0)\n",
    "\n",
    "  # True FOB on validation (continuous)\n",
    "  y_true = np.array([fromClasses(c) for c in y_val_class])\n",
    "\n",
    "  # Most likely class -> FOB\n",
    "  y_pred_mode = []\n",
    "  for yp in y_hat:\n",
    "    cls = np.argmax(yp)\n",
    "    y_pred_mode.append(fromClasses(cls))\n",
    "\n",
    "  # Expected FOB (probability-weighted over classes)\n",
    "  y_exp = []\n",
    "  class_indices = np.arange(NUMCLASSES)\n",
    "  for yp in y_hat:\n",
    "    exp_class = np.sum(yp * class_indices)\n",
    "    y_exp_val = fromClasses(exp_class)\n",
    "    y_exp.append(y_exp_val)\n",
    "\n",
    "  # Lower & upper bounds from class distribution (ALPHA)\n",
    "  y_low = []\n",
    "  for yp in y_hat:\n",
    "    prob_running = 0.0\n",
    "    l = yp.shape[0]\n",
    "    for c in range(l):\n",
    "      prob_running += yp[c]\n",
    "      if prob_running > ALPHA / 2:\n",
    "        y_low.append(fromClasses(c))\n",
    "        break\n",
    "\n",
    "  y_high = []\n",
    "  for yp in y_hat:\n",
    "    prob_running = 0.0\n",
    "    l = yp.shape[0]\n",
    "    for c in range(l - 1, -1, -1):\n",
    "      prob_running += yp[c]\n",
    "      if prob_running > ALPHA / 2:\n",
    "        y_high.append(fromClasses(c))\n",
    "        break\n",
    "\n",
    "  # 10) Plot (now this is FOB for Sweden fish, not \"goods to USA\")\n",
    "  plt.figure(figsize=(12, 5))\n",
    "  plt.plot(y_true, label=\"Actual FOB\")\n",
    "  plt.plot(y_pred_mode, label=\"Predicted FOB (most likely class)\")\n",
    "  plt.plot(y_exp, label=\"Expected FOB (expectation over classes)\")\n",
    "  plt.plot(y_low,  label=f\"Lower bound (α/2={ALPHA/2:.3f})\")\n",
    "  plt.plot(y_high, label=f\"Upper bound (α/2={ALPHA/2:.3f})\")\n",
    "  plt.title(\"FOB exports – classification LSTM with FX, CPI, Tonnes, FOB features\")\n",
    "  plt.xlabel(\"Validation time steps\")\n",
    "  plt.ylabel(\"FOB value\")\n",
    "  plt.legend()\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "  # 11) Metrics on expected FOB\n",
    "  r2 = r2_score(y_true, y_exp)\n",
    "  wape = calculate_wape(y_true, y_exp)\n",
    "  accuracy = 100 - wape\n",
    "\n",
    "  print(f\"R-squared on the validation set: {r2:.4f}\")\n",
    "  print(f\"Weighted Absolute Percentage Error (WAPE): {wape:.4f}\")\n",
    "  print(f\"The model explains {r2*100:.2f}% of variance, \"\n",
    "        f\"average error (WAPE) {wape:.2f}% → approx accuracy {accuracy:.2f}%\")\n",
    "  print(\"Number of merged months used:\", len(fob))\n",
    "\n",
    "  # Return stuff you might want in a second cell\n",
    "  return target_classes, model, X_train, y_val, y_exp, targets\n",
    "\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "  target_classes, model, X_train, y_val, y_exp, targets = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01158a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Plot future predictions using only sales data\n",
    "# ---------------------------------------------------\n",
    "def plotting(validation_months_indices,future_months_indices_sales_only, future_predictions_sales_only, targets, y_val, y_pred, y_std, y_mean ):\n",
    "  try:\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(np.arange(len(targets)), targets, label=\"Actual Sales (Historical)\")\n",
    "    plt.plot(validation_months_indices, y_val * y_std + y_mean, label=\"Actual Sales (Validation)\")\n",
    "    plt.plot(validation_months_indices, y_pred, label=\"Predicted Sales (Validation - Original Model)\")                # Using y_pred from the first cell\n",
    "    plt.plot(future_months_indices_sales_only, future_predictions_sales_only, label=\"Predicted Sales (Future - Sales Only)\", linestyle='--')\n",
    "    plt.title(\"Sales of export Services, Prediction and Future (Sales Only Input)\")\n",
    "    plt.xlabel(\"Months\")\n",
    "    plt.ylabel(\"Sales (MISK)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "  except Exception as e:\n",
    "    print(f\"Error in plotting: {e}\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Predict future sales using only historical sales data\n",
    "# -------------------------------------------------------\n",
    "def main(targets_n, y_std, y_mean, model, X_train, y_val, y_pred, targets):                                           # Call the main function from the previous cell to get the variables\n",
    "                                                                                                                      # The variables are now passed as arguments to this main function\n",
    "  last_sales_sequence_n = targets_n[-lookback:]                                                                       # Get the last 'lookback' data points from the normalized historical sales data\n",
    "  future_predictions_sales_only_n = []                                                                                # List to store future normalized predictions\n",
    "  num_future_months = 24\n",
    "  try:                                                                                                                # Number of months to predict into the future\n",
    "    current_sales_sequence_n = last_sales_sequence_n.copy()                                                           # Initialize the current sequence for prediction\n",
    "    for i in range(num_future_months):                                                                                # Reshape the current sequence to match the model's input shape (1, lookback, num_features)\n",
    "      input_sequence = current_sales_sequence_n.reshape(1, lookback, 1)                                               # Since we only have one feature (sales or goods), the shape is (1, lookback, 1)\n",
    "      next_sales_n = model.predict(input_sequence, verbose=0)                                                         # Predict the next sales value (normalized). verbose=0 to reduce output during prediction\n",
    "      future_predictions_sales_only_n.append(next_sales_n[0, 0])                                                      # Append the predicted sales to the future predictions list\n",
    "      current_sales_sequence_n = np.roll(current_sales_sequence_n, -1)                                                # Update the current sequence by removing the first value and adding the predicted value\n",
    "      current_sales_sequence_n[-1] = next_sales_n[0, 0]\n",
    "    future_predictions_sales_only = np.array(future_predictions_sales_only_n) * y_std + y_mean                        # Denormalize the future predictions\n",
    "    last_historical_month = len(targets)                                                                              # Calculate the time indices for the future predictions\n",
    "    future_months_indices_sales_only = np.arange(last_historical_month, last_historical_month + num_future_months)\n",
    "    start_index_validation = lookback + len(X_train)                                                                  # Calculate the time indices for the validation data (copied from the previous cell for plotting)\n",
    "    validation_months_indices = np.arange(start_index_validation, start_index_validation + len(y_val))\n",
    "  except Exception as e:\n",
    "    print(f\"Error in predicting future sales using only historical sales data: {e}\")\n",
    "\n",
    "  plotting(validation_months_indices,future_months_indices_sales_only,future_predictions_sales_only, targets, y_val, y_pred, y_std, y_mean )\n",
    "  print(\"Future Export of services to 250 countries Predictions (next {} months - Sales Only):\".format(num_future_months))\n",
    "  print(future_predictions_sales_only)\n",
    "main(targets_n, y_std, y_mean, model, X_train, y_val, y_pred, targets)                                                # Call the main function from the previous cell and pass its return values to the second main function\n",
    "                                                                                                                      # Assuming the first cell has been executed and its variables are in the global scope"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haghackvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
